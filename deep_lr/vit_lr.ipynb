{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vision transformer\n",
    "学习"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:02:53.968291Z",
     "start_time": "2024-08-05T11:02:52.633620Z"
    }
   },
   "source": [
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:02:54.820545Z",
     "start_time": "2024-08-05T11:02:54.815338Z"
    }
   },
   "source": [
    "class PathEmbed(nn.Module):\n",
    "    \"\"\"2d images to path Embedding \n",
    "    \"\"\"\n",
    "    def __init__(self, image_size = 224, path_size = 16, in_c = 3, embed_dim = 768, norm_layer = None):\n",
    "        super().__init__()\n",
    "        image_size=(image_size, image_size)\n",
    "        path_size = (path_size, path_size)\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = path_size\n",
    "        self.grid_size = (image_size[0] // path_size[0], image_size[1] // path_size[1])\n",
    "        self.num_patches = self.grid_size[0]*self.grid_size[1]\n",
    "\n",
    "\n",
    "        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=path_size, stride=path_size) # 按照默认参数 输出维度是 768 * 14 * 14\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B,C,H,W = x.shape\n",
    "        assert H == self.image_size[0] and W == self.image_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.image_size[0]}*{self.image_size[1]}).\"\n",
    "        \n",
    "        # flatten: [B, C, H, W] -> [B, C, HW]\n",
    "        # transpose: [B, C, HW] -> [B, HW, C]\n",
    "        x = self.proj(x).flatten(2).transpose(1,2)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        return x\n",
    " "
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:02:54.970875Z",
     "start_time": "2024-08-05T11:02:54.967122Z"
    }
   },
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim, # 输入token的dim\n",
    "                 num_heads=False,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 attn_drop_ratio=0.,\n",
    "                 proj_drop_ratio=0.\n",
    "                 ):\n",
    "        super(Attention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.qkv = nn.Linear(dim, dim*3, bias=qkv_bias) # 将x--3倍维度扩张-->q k v\n",
    "        self.atten_drop = nn.Dropout(attn_drop_ratio)\n",
    "        self.proj = nn.Linear(dim,dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop_ratio)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,N,C = x.shape # 1，2，6\n",
    "        # self.qkv(x)->1,2,9\n",
    "        # permute 维度置换 3(代表q、k、v),batch 1,head 3, 序列2, 嵌入2\n",
    "        qkv = self.qkv(x).reshape(B,N,3,self.num_heads,\n",
    "                                  C//self.num_heads).permute(2,0,3,1,4) \n",
    "        q,k,v = qkv[0],qkv[1],qkv[2] \n",
    "\n",
    "        attn = (q@k.tanspose(-2,-1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.atten_drop(attn)\n",
    "\n",
    "\n",
    "        x = (attn @ v).transpose(1,2).reshape(B,N,C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "        \n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:02:55.112408Z",
     "start_time": "2024-08-05T11:02:55.109178Z"
    }
   },
   "source": [
    "def drop_path(x, drop_prob:float=0., training:bool=False):\n",
    "    \"\"\"\n",
    "    参考连接: https://blog.csdn.net/qq_43135204/article/details/127912029\n",
    "    \n",
    "    :param x: \n",
    "    :param drop_prob: \n",
    "    :param training: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if drop_prob == 0 or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0], ) + (1, ) * (x.ndim - 1) # x的第一维度,x的维度数 \n",
    "\n",
    "\n",
    "    # 随机均匀的在(0,1]上生成shape形状的tensor每个点加上keep_prob\n",
    "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "    # print(random_tensor)\n",
    "    random_tensor.floor_()# 向下取整操作\n",
    "    # print(random_tensor)\n",
    "    \n",
    "    #将x中的每个元素除以keep_prob（放缩操作） 然后乘以random_tensor 这里巧妙的利用的广播机制\n",
    "    # 意义在于 rt经过向下取整后只有0/1可以忽略为0的位置，这里放缩理解不是很清晰应该是加大存在元素的影响\n",
    "    output = x.div(keep_prob) * random_tensor \n",
    "\n",
    "    return output"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:02:55.258557Z",
     "start_time": "2024-08-05T11:02:55.255708Z"
    }
   },
   "source": [
    "class DropPath(nn.Module):\n",
    "    \"\"\"\n",
    "    Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    每个样本的下降路径（随机深度）（当应用于残余块的主路径时）。\"\"\"\n",
    "    \n",
    "    def __init__(self,drop_prob = None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return drop_path(x,self.drop_prob, self.training)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:02:55.475491Z",
     "start_time": "2024-08-05T11:02:55.472360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None,act_layer=nn.GELU,drop=0):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:02:55.612317Z",
     "start_time": "2024-08-05T11:02:55.608752Z"
    }
   },
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim,\n",
    "                 num_heads,\n",
    "                 mlp_ratio=4,\n",
    "                 qkv_bias=False,\n",
    "                 qk_scale=None,\n",
    "                 drop_ratio=0.,\n",
    "                 attn_drop_ratio=0.,\n",
    "                 drop_path_ratio=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer = nn.LayerNorm\n",
    "                 ):\n",
    "        super(Block, self).__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(dim,num_heads=num_heads,qkv_bias=qkv_bias,qk_scale=qk_scale,\n",
    "                              attn_drop_ratio=attn_drop_ratio, proj_drop_ratio=drop_path_ratio\n",
    "                              )\n",
    "        self.drop_path = DropPath(drop_path_ratio) if drop_path_ratio >0. else nn.Identity()   #todo\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp=MLP(in_features=dim,\n",
    "                     hidden_features=mlp_hidden_dim,\n",
    "                     act_layer=act_layer,\n",
    "                     drop=drop_ratio)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:13:20.380177Z",
     "start_time": "2024-08-05T11:13:20.370522Z"
    }
   },
   "cell_type": "code",
   "source": "nn.Linear",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.linear.Linear"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:25:28.803865Z",
     "start_time": "2024-08-05T11:25:28.797511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _init_vit_weight(m):\n",
    "    # todo learn\n",
    "    \"\"\"\n",
    "    这个函数是没有返回值的，\n",
    "    m是穿参是个临时变量\n",
    "    这里初始化的是nn下网络\n",
    "    :param m: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.trunc_normal_(m.weight, std=0.01)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.zeros_(m.bias)\n",
    "            nn.init.zeros_(m.weight)\n",
    "        \n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:32:46.046462Z",
     "start_time": "2024-08-05T11:32:46.033183Z"
    }
   },
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "   def __init__(self, image_size=224, path_size=16, in_c=3, num_classes=1000,\n",
    "                embed_dim=768, depth=12, num_heads=12,mlp_ratio=4.0,qkv_bias=True,\n",
    "                qk_scale=None, representataion_size=None, distilled=False,drop_ratio=0.,\n",
    "                attn_drop_ration=0., drop_path_ratio=0.5,embed_layer=PathEmbed,norm_layer=None,\n",
    "                act_layer=None\n",
    "                ):\n",
    "       \"\"\"_summary_\n",
    "\n",
    "       Args:\n",
    "           image_size (int, optional): 图片输入的size.\n",
    "           path_size (int, optional): 图片每个path的size.\n",
    "           in_c (int, optional): 图片输入的通道数.\n",
    "           number_classes (int, optional):分类数\n",
    "           embed_dim (int, optional): 嵌入维度\n",
    "           depth (int, optional): transformer 深度 ？\n",
    "           num_heads (int, optional): 注意力头数\n",
    "           mlp_ratio (float, optional): mlp嵌入跟词嵌入的维度比例\n",
    "           qkv_bias (bool, optional): 是否需要qkv权重的偏置项\n",
    "           qk_scale (_type_, optional): _description_. Defaults to None.\n",
    "           representation (_type_, optional): _description_. Defaults to None.\n",
    "           distilled (bool, optional): _description_. Defaults to False.\n",
    "           drop_ratio (_type_, optional): drop指标.\n",
    "           attn_drop_ration (_type_, optional): _description_. Defaults to 0..\n",
    "           drop_path_ratio (float, optional): _description_. Defaults to 0.5.\n",
    "           embed_layer (_type_, optional): _description_. Defaults to PathEmbed.\n",
    "           norm_layer (_type_, optional): _description_. Defaults to None.\n",
    "           act_layer (_type_, optional): _description_. Defaults to None.\n",
    "       \"\"\"\n",
    "       super(VisionTransformer, self).__init__()\n",
    "       self.num_classes = num_classes\n",
    "       self.num_features = self.embed_dim=embed_dim\n",
    "        \n",
    "       self.num_tokens = 2 if distilled else 1\n",
    "       norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6)\n",
    "       act_layer = act_layer or nn.GELU\n",
    "\n",
    "       self.patch_embed = embed_layer(image_size=image_size, path_size=path_size, in_c=in_c, embed_dim=embed_dim)\n",
    "       num_patches = self.patch_embed.num_patches\n",
    "\n",
    "       self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "       self.dist_token = nn.Parameter(torch.zeros(1,1,embed_dim)) if distilled else None\n",
    "       self.pos_embed = nn.Parameter(torch.zeros(1, num_patches+self.num_tokens, embed_dim))\n",
    "       self.pos_drop = nn.Dropout(p=drop_ratio)\n",
    "\n",
    "       dpr = [x.item() for x in torch.linspace(0, drop_path_ratio, depth)] # stochastic depth decay rule 随机深度衰减规则\n",
    "       self.blocks = nn.Sequential(*[\n",
    "           Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias,qk_scale=qk_scale,\n",
    "                 drop_ratio=drop_ratio,attn_drop_ratio=attn_drop_ration, drop_path_ratio=dpr[i],\n",
    "                 norm_layer=norm_layer, act_layer=act_layer)\n",
    "           for i in range(depth)\n",
    "       ])\n",
    "       self.norm = norm_layer(embed_dim)\n",
    "       \n",
    "       if representataion_size and not distilled:\n",
    "           self.has_logits = True\n",
    "           self.num_features = representataion_size\n",
    "           self.pre_logits = nn.Sequential(OrderedDict([\n",
    "               (\"fc\", nn.Linear(embed_dim, representataion_size)),\n",
    "               ('act',nn.Tanh())\n",
    "           ]))\n",
    "       else:\n",
    "           self.has_logits= False\n",
    "           self.pre_logits=nn.Identity()\n",
    "       self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "       self.head_dist = None\n",
    "       if distilled:\n",
    "           self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if num_classes > 0 else nn.Identity()\n",
    "           \n",
    "       nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "       if self.dist_token is not None:\n",
    "           nn.init.trunc_normal_(self.dist_token, std=0.02)\n",
    "       nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "       self.apply(_init_vit_weight)\n",
    "       \n",
    "   def forward_features(self, x):\n",
    "       x = self.patch_embed(x)\n",
    "       \n",
    "       cls_token = self.cls_token.expand(x.shape[0], -1,-1)\n",
    "       if self.dist_token is None:\n",
    "           x = torch.cat((cls_token, x), dim=1)\n",
    "       else:\n",
    "           x = torch.cat((cls_token, self.dist_token.expand(x.shape[0], -1, -1),x),dim=1)\n",
    "      \n",
    "       x = self.pos_drop(x + self.pos_embed)\n",
    "       x = self.blocks(x)\n",
    "       x = self.norm(x)\n",
    "       if self.dist_token is None:\n",
    "           return self.pre_logits(x[:,0])\n",
    "       else:\n",
    "           return x[:,0],x[:1]\n",
    "   \n",
    "   def forward(self, x):\n",
    "       x = self.forward_features(x)\n",
    "       if self.head_dist is not None:\n",
    "           x, x_dist = self.head(x[0], self.head_dist(x[1]))\n",
    "           if self.training and not torch.jit.is_scripting():\n",
    "               return x, x_dist\n",
    "           else:\n",
    "               return (x + x_dist) / 2\n",
    "       else:\n",
    "           x = self.head(x)\n",
    "       return x\n",
    "           \n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "       \n",
    "       "
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchv01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
