{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T03:45:21.872165Z",
     "start_time": "2024-07-29T03:45:20.327802Z"
    }
   },
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, GPT2LMHeadModel\n",
    "from torch.nn import CrossEntropyLoss"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T03:45:21.874537Z",
     "start_time": "2024-07-29T03:45:21.873006Z"
    }
   },
   "source": [
    "# ! pip install accelerate"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T03:45:21.880768Z",
     "start_time": "2024-07-29T03:45:21.875237Z"
    }
   },
   "source": [
    "class Ppl(object):\n",
    "    def __init__(self,model_path) -> None:\n",
    "        self.device = torch.device('cude:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_path, \n",
    "                                                          device_map=\"auto\",\n",
    "                                                        #   torch_dtype=torch.float16,\n",
    "                                                          trust_remote_code=True)\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def cpmpute(self, text, max_length=50):\n",
    "        inputs = self.tokenizer(text, padding=\"max_length\",max_length=max_length, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        # inputs = self.tokenizer(text, padding='max_length',max_length=max_length, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        print(\"inputs:\",inputs)\n",
    "        bs, sl = inputs['input_ids'].size()\n",
    "        print(\"bs:\",bs)\n",
    "        print(\"sl:\",sl)\n",
    "        # outputs = self.model(**inputs, labels = inputs['input_ids'])\n",
    "        outputs = self.model(**inputs, labels = inputs['input_ids'])\n",
    "        # print(\"outputs:\",outputs)\n",
    "        for item in outputs:\n",
    "            print(item)\n",
    "        logits=outputs[1]\n",
    "        print(\"logits:\",logits)\n",
    "        print(logits.shape)\n",
    "\n",
    "        shift_logits = logits[:, :-1, :].contiguous()\n",
    "        print(\"shift_logits:\",shift_logits)\n",
    "        print(shift_logits.shape)\n",
    "\n",
    "        shift_labels = inputs[\"input_ids\"][:,1:].contiguous()\n",
    "        print(\"shitf_labels:\",shift_labels)\n",
    "        print(shift_labels.shape)\n",
    "        shift_attentions = inputs[\"attention_mask\"][:, 1:].contiguous()\n",
    "        print(\"shift_attentions:\",shift_attentions)\n",
    "        print(shift_attentions.shape)\n",
    "\n",
    "        loss_fct = CrossEntropyLoss(ignore_index=0,reduction=\"none\")\n",
    "        print(\"loss_fct:\",loss_fct)\n",
    "\n",
    "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1)).detach().reshape(bs, -1)\n",
    "        print(\"loss:\",loss)\n",
    "\n",
    "        meanloss=loss.sum(1) / shift_attentions.sum(1)\n",
    "        print(\"meanloss:\",meanloss)\n",
    "\n",
    "        ppl = torch.exp(meanloss).cpu().numpy()\n",
    "        return ppl\n",
    "\n",
    "        \n",
    "        "
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T03:45:22.813797Z",
     "start_time": "2024-07-29T03:45:21.882222Z"
    }
   },
   "source": [
    "plm_path = \"/Users/alexfeng/Desktop/alex/code/work_lr/deep_lr/hgmodel/gpt2_chinese_cluecorpussmall\"\n",
    "ppl_metric = Ppl(plm_path)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T03:45:24.247311Z",
     "start_time": "2024-07-29T03:45:24.151301Z"
    }
   },
   "source": [
    "text = \"你好\"\n",
    "ppl_metric.cpmpute(text=text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: {'input_ids': tensor([[ 101,  872, 1962,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]])}\n",
      "bs: 1\n",
      "sl: 50\n",
      "loss\n",
      "logits\n",
      "past_key_values\n",
      "logits: tensor([[[ -9.9143,  -9.7647,  -9.8217,  ...,  -9.6961,  -9.7799,  -9.6771],\n",
      "         [-10.1989, -10.5101, -10.8450,  ..., -10.3173, -10.1622, -10.3776],\n",
      "         [ -8.9859,  -8.9851,  -9.3672,  ...,  -8.3492,  -8.3073,  -8.9679],\n",
      "         ...,\n",
      "         [ -5.9194,  -6.6286,  -6.2972,  ...,  -6.3196,  -6.7312,  -6.4365],\n",
      "         [ -5.8329,  -6.5810,  -6.2172,  ...,  -6.3098,  -6.6891,  -6.3533],\n",
      "         [ -5.8693,  -6.5515,  -6.2280,  ...,  -6.2797,  -6.6510,  -6.3497]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch.Size([1, 50, 21128])\n",
      "shift_logits: tensor([[[ -9.9143,  -9.7647,  -9.8217,  ...,  -9.6961,  -9.7799,  -9.6771],\n",
      "         [-10.1989, -10.5101, -10.8450,  ..., -10.3173, -10.1622, -10.3776],\n",
      "         [ -8.9859,  -8.9851,  -9.3672,  ...,  -8.3492,  -8.3073,  -8.9679],\n",
      "         ...,\n",
      "         [ -5.8658,  -6.5784,  -6.2453,  ...,  -6.2924,  -6.6640,  -6.3776],\n",
      "         [ -5.9194,  -6.6286,  -6.2972,  ...,  -6.3196,  -6.7312,  -6.4365],\n",
      "         [ -5.8329,  -6.5810,  -6.2172,  ...,  -6.3098,  -6.6891,  -6.3533]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 49, 21128])\n",
      "shitf_labels: tensor([[ 872, 1962,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0]])\n",
      "torch.Size([1, 49])\n",
      "shift_attentions: tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])\n",
      "torch.Size([1, 49])\n",
      "loss_fct: CrossEntropyLoss()\n",
      "loss: tensor([[4.1438, 5.2409, 5.7104, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "meanloss: tensor([5.0317])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([153.19353], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T03:37:43.993172Z",
     "start_time": "2024-07-29T03:37:43.991825Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchv01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
